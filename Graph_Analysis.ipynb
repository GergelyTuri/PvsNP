{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Theoretical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import SigProc\n",
    "import analysis_utils as au\n",
    "from scipy import stats\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE_RAW_DRD87 = \"/Users/saveliyyusufov/Hen_Lab/Mice/drd87_experiments/Raw_EPM_drd87.csv\"\n",
    "data = pd.read_csv(TRACE_RAW_DRD87, header=None)\n",
    "z_scored_dataframe, AUC_dataframe, cell_transients_dataframe = SigProc.detect_ca_transients_mossy(data, 2, 0.5, 0.2, 10)\n",
    "\n",
    "# Rename all the columns from \"neuron_x\" --> \"x\". This makes the graphs neater by making sure the neuron names fit into the nodes\n",
    "cell_transients_dataframe.columns = [i for i in range(1, len(cell_transients_dataframe.columns)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(dataframe):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(dataframe.columns)\n",
    "    corr_pairs = au.find_correlated_pairs(dataframe, correlation_coeff=0.3)\n",
    "\n",
    "    for key in corr_pairs:\n",
    "        G.add_edge(key[0], key[1], weight=round(corr_pairs[key], 3))\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_graph(dataframe):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(dataframe.columns)\n",
    "    corr_pairs = au.find_correlated_pairs(dataframe, correlation_coeff=0.3)\n",
    "\n",
    "    # Connect a len(correlated_pairs_dict) amount of random edges between all the nodes in the random graph\n",
    "    for i in range(len(corr_pairs)):\n",
    "        G.add_edge(np.random.randint(1, len(dataframe.columns)+1), np.random.randint(1, len(dataframe.columns)+1))\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(G):\n",
    "\n",
    "    # positions for all nodes\n",
    "    pos = nx.spring_layout(G, weight='weight') \n",
    "\n",
    "    plt.figure(figsize=(35, 35))\n",
    "\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=1000, node_color='lightblue');\n",
    "\n",
    "    edges, weights = zip(*nx.get_edge_attributes(G, 'weight').items())\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, width=3.0, edge_color=weights, edge_cmap=plt.cm.YlGnBu);\n",
    "\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=15, edge_labels=labels)\n",
    "\n",
    "    plt.axis('off');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_graph(random_graph):\n",
    "    \n",
    "    # positions for all nodes\n",
    "    pos = nx.spring_layout(random_graph, weight='weight') \n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(random_graph, pos, node_size=700, node_color='lightblue');\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(random_graph, pos, width=1.0); \n",
    "\n",
    "    labels = nx.get_edge_attributes(random_graph, 'weight')\n",
    "    nx.draw_networkx_edge_labels(random_graph, pos, edge_labels=labels)\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(random_graph, pos, font_size=15, edge_labels=labels)\n",
    "\n",
    "    plt.axis('off');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.approximation import clique\n",
    "def compute_network_measures(graph):\n",
    "    \"\"\"\n",
    "    \n",
    "    args:\n",
    "    \n",
    "    returns:\n",
    "    \"\"\"\n",
    "    network_measures_dict = dict()\n",
    "    network_measures_dict[\"assortativity\"] = nx.degree_assortativity_coefficient(graph) \n",
    "    network_measures_dict[\"mean betweenness centrality\"] = compute_mean_betweenness_centrality(graph)\n",
    "    #network_measures_dict[\"mean clique size\"] = \n",
    "    network_measures_dict[\"max clique size\"] = len(clique.max_clique(graph))\n",
    "    network_measures_dict[\"clustering coefficient\"] = nx.clustering(graph)\n",
    "    #network_measures_dict[\"mean path length\"] = \n",
    "    \n",
    "    return network_measures_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_betweenness_centrality(graph):\n",
    "    graph_centrality = nx.betweenness_centrality(graph)\n",
    "    return np.mean(list(graph_centrality.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we plot an undirected graph of the network of cells that were imaged for a given mouse\n",
    "- Edges are added between pairs of neurons that had a correlation coefficient $\\ge 3.0$\n",
    "    - Each edge is weighted by the correlation coefficient corresponding to the two neurons it connects\n",
    "    - The correlation coefficient between each corresponding pair of neurons is drawn on the edge between them\n",
    "    - The color of each edge is determined by the correlation between the pair of neurons: \n",
    "        - yellow - correlated\n",
    "        - green - strongly correlated \n",
    "        - blue - very strongly correlated\n",
    "- Isolate nodes are also plotted\n",
    "- No clustering algorithm was applied to this network of nodes... the graph drawing algorithm that was utilized keeps corresponding nodes clustered together by accounting for the weights of the edges\n",
    "- Note that the clusters of nodes strongly correspond to the clusters created by the Seaborn library's cluster map data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_graph = create_graph(cell_transients_dataframe)\n",
    "plot_graph(total_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The degree of a node is the number of edges that link it to the rest of the network. According to Bullmore et al. 2009, node degree is the most fundamental network measure, and most other measures are ultimately linked to node degree. \n",
    "### So, we output a dictionary that contains each node (neuron) in the network and its corresponding degree\n",
    "- For the sake of curiosity, we retrieve the name of the node that has the greatest degree in this particular network\n",
    "    - As we can see, in the case of the dataset for drd87, the degree of node (neuron) $29$ is $11$, and this is the largest degree of any node for this particular network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dict(total_graph.degree()), key=dict(total_graph.degree()).get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple bar plot that depicts the degree of each node (neuron) in the network\n",
    "- Using this plot, we can see that node $29$ does indeed have the highest degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (18, 8)})\n",
    "sns.barplot(x=list(dict(total_graph.degree()).keys()), y=list(dict(total_graph.degree()).values()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## According to Bullmore et al. 2009, in random networks, all connections are equally probable, resulting in a Gaussian degree distribution. In complex networks, the degree distributions are non-Gaussian, and often have a long tail towards high degrees. \n",
    "### So, we plot the distribution of the degrees of all the nodes (neurons) in our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (14, 4)})\n",
    "sns.distplot(list(dict(total_graph.degree()).values()), color='m', fit=stats.norm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_graph_centrality = nx.betweenness_centrality(total_graph)\n",
    "max(total_graph_centrality, key=total_graph_centrality.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the [Betweenness centrality](https://en.wikipedia.org/wiki/Betweenness_centrality) algorithm, we find that node (neuron) 33 has the highest centrality in this network\n",
    "### Hubs are nodes with high degree, or high centrality. The centrality of a node measures how many of the shortest paths between all other node pairs in the network pass through it. A node with high centrality is thus crucial to efficient communication (Bullmore et al. 2009)\n",
    "### Going off of this, we can assume that node (neuron) 33 is a hub in this partricular network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (18, 8)})\n",
    "sns.barplot(x=list(total_graph_centrality.keys()), y=list(total_graph_centrality.values()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In accordance with Bullmore et al. 2009, our network measures must be compared with the (null) distribution of equivalent parameters estimated in random networks containing the same number of nodes and connections. \n",
    "> \"Statistical testing of network parameters may best be conducted by permutation- or resampling-based methods of non-parametric inference given the lack of statistical theory concerning the distribution of most network metrics.\" (Bullmore et al. 2009)\n",
    "\n",
    "## So, we begin by plotting an undirected graph of the $69$ nodes (neurons) from our dataset and we draw $184$ edges between $92$ (the amount of correlated neurons in our dataset) randomly selected pairs of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graph = create_random_graph(cell_transients_dataframe)\n",
    "plot_random_graph(random_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We quickly plot a degree distribution plot for this random network to see if it is Gaussian \n",
    "- recall that a random network should have Gaussian degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (14, 4)})\n",
    "sns.distplot(list(dict(random_graph.degree()).values()), color='m', fit=stats.norm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We compute the betweenness centrality of this random network to see whether the centrality measure of the complex network is actually significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_graph_centrality = nx.betweenness_centrality(random_graph)\n",
    "max(random_graph_centrality, key=random_graph_centrality.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_column_names = ['Trial_time', 'Recording_time', 'X_center', 'Y_center', 'Area', 'Areachange', \n",
    "                         'Elongation', 'Distance_moved', 'Velocity', 'Arena_centerpoint',\n",
    "                         'Open1_centerpoint', 'Open2_centerpoint',\n",
    "                         'Closed1_centerpoint', 'Closed2_centerpoint',\n",
    "                         'OpenArms_centerpoint', 'ClosedArms_centerpoint', 'Result_1']\n",
    "\n",
    "activity_df = pd.read_csv('/Users/saveliyyusufov/Hen_Lab/Mice/drd87_experiments/activity_drd87.csv', header=None)\n",
    "behavior_df = pd.read_csv('/Users/saveliyyusufov/Hen_Lab/Mice/drd87_experiments/behavior_drd87.csv', header=None)\n",
    "\n",
    "# Save only every nth row in order to downsample behavior Dataframes from 30fps -> 10fps\n",
    "ROW_MULTIPLE = 3\n",
    "behavior_df.drop(behavior_df.index[[i for i in range(0, len(behavior_df.index)) if i % ROW_MULTIPLE != 0]], inplace=True)\n",
    "\n",
    "# For the activity Dataframe, we Change column names to corresponding neuron names \n",
    "activity_df.columns = ['neuron' + str(i) for i in range(1, len(activity_df.columns) + 1)]\n",
    "\n",
    "# Change column names to the behavior column names found in the MossyEPM, MATLAB struct\n",
    "behavior_df.columns = behavior_column_names\n",
    "\n",
    "# Fix indexing after downsample\n",
    "behavior_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Make the behavior Dataframe and the activity Dataframe have the same amount of rows \n",
    "if len(behavior_df.index) > len(activity_df.index):\n",
    "    diff = len(behavior_df.index) - len(activity_df.index)\n",
    "    behavior_df = behavior_df[:-diff]\n",
    "elif len(behavior_df.index) < len(activity_df.index):\n",
    "    diff = len(activity_df.index) - len(behavior_df.index)\n",
    "    activity_df = activity_df[:-diff]\n",
    "\n",
    "# Define running frames\n",
    "VELOCITY_CUTOFF = 4;\n",
    "\n",
    "# Adds column to the end of the behavior Dataframe and make each cell in that column a 0 \n",
    "# if the corresponding velocity < VELOCITY_CUTOFF or a 1 if the corresponding velocity >= VELOCITY_CUTOFF\n",
    "# TODO: Utilize a pandas Series instead of a list comprehension in the line below\n",
    "behavior_df['Running_frames'] = [1 if velocity > VELOCITY_CUTOFF else 0 for velocity in behavior_df['Velocity'].tolist()]\n",
    "\n",
    "AUC_dataframe.columns = ['neuron' + str(i) for i in range(1, len(AUC_dataframe.columns)+1)]\n",
    "result_dataframe = pd.concat([cell_transients_dataframe, behavior_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We plot the network of neurons for all of the time that the given mouse was in the closed arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the result_dataframe, we get the indices for when the mouse was in ClosedArms_centerpoint\n",
    "indices = result_dataframe.loc[result_dataframe[\"OpenArms_centerpoint\"] != 0].index\n",
    "\n",
    "open_arms_graph = create_graph(cell_transients_dataframe.iloc[indices])\n",
    "plot_graph(open_arms_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (14, 4)})\n",
    "sns.distplot(list(dict(open_arms_graph.degree()).values()), color='m', fit=stats.norm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dict(open_arms_graph.degree()), key=dict(open_arms_graph.degree()).get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_arms_graph_centrality = nx.betweenness_centrality(open_arms_graph)\n",
    "max(open_arms_graph_centrality, key=open_arms_graph_centrality.get)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
