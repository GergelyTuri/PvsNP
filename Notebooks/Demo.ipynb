{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import warnings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import normalized_mutual_info_score \n",
    "\n",
    "# We need to be able to access the files/directories outside of the `Notebooks` directory.\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "from analysis import visualize\n",
    "from analysis.resampling import Resampler\n",
    "from analysis.graph_analysis import NeuronNetwork\n",
    "from analysis.place_cell_analysis import apply_cantor_pairing\n",
    "from analysis.clustering import affinity_propagation, extract_clusters\n",
    "from analysis.analysis_utils import Mouse, find_file, extract_epochs, filter_epochs, downsample_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# This is to supress future warnings about sklearn's nmi function.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We load & preprocess the data for a mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv(\"data/artificial_epm_s.csv\", header=0)\n",
    "c = pd.read_csv(\"data/artificial_epm_c.csv\", header=0)\n",
    "behavior = pd.read_csv(\"data/epm_behavior.csv\", header=0)\n",
    "\n",
    "# For convenience, cast every column name to an int.\n",
    "s.columns = [int(col) for col in s.columns]\n",
    "c.columns = [int(col) for col in c.columns]\n",
    "\n",
    "behavior_column_names = ['X_center',\n",
    "                         'Y_center',\n",
    "                         'Area',\n",
    "                         'Areachange',\n",
    "                         'Elongation',\n",
    "                         'Distance_moved',\n",
    "                         'Velocity',\n",
    "                         'Arena_centerpoint',\n",
    "                         'Open1_centerpoint',\n",
    "                         'Open2_centerpoint',\n",
    "                         'Closed1_centerpoint',\n",
    "                         'Closed2_centerpoint',\n",
    "                         'OpenArms_centerpoint',\n",
    "                         'ClosedArms_centerpoint',\n",
    "                         'Hardware_command',\n",
    "                         'Hardware_command_2',\n",
    "                         'Hardware_command_3',\n",
    "                         'Hardware_command_4',\n",
    "                         'Result_1']\n",
    "\n",
    "# Drop every 3rd row from the behavior dataframe\n",
    "behavior = downsample_dataframe(behavior, 3)\n",
    "\n",
    "# Rename the behavior dataframe columns and drop all useless column vectors.\n",
    "behavior.columns = behavior_column_names\n",
    "behavior.drop([\"Hardware_command\", \"Hardware_command_2\", \"Hardware_command_3\", \"Hardware_command_4\", \"Result_1\"], axis=1, inplace=True)\n",
    "\n",
    "# We add a time series column using Timedelta, where the amount of periods is the current\n",
    "# total amount of frames in the dataframe. 10 fps implies 100 milliseconds (ms) per frame, \n",
    "# so we set each period to be 100 ms long.\n",
    "behavior = behavior.assign(Trial_time=pd.timedelta_range(0, periods=len(behavior.index), freq=\"100ms\"))\n",
    "\n",
    "# Create a Mouse object to store all of the data for a particular mouse\n",
    "mickey = Mouse(name=\"Mickey\", age=1, sex='M', cell_transients=c, spikes=s, behavior=behavior)\n",
    "\n",
    "# Convert dataframe to a boolean matrix, where spikes := 1 and no spike := 0\n",
    "# mickey.spikes = mickey.spikes.where(mickey.spikes==0, 1)\n",
    "\n",
    "# Add \"Center\" column to concatenated dataframe\n",
    "center = (mickey.spikes_and_beh[\"OpenArms_centerpoint\"]) + (mickey.spikes_and_beh[\"ClosedArms_centerpoint\"])\n",
    "center = 1-center\n",
    "mickey.spikes_and_beh[\"Center\"] = center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a heatmap and a \"true\" scatterplot for a single neuron.\n",
    "#### The heatmap below does *not* take \"time spent in bins\" or anything else into account. If you want to account for such things, the onus is on you to set the weights and/or \"bin\" your data as you see fit. `plot_heatmap` was implemented to be as useful as possible for as many people as possible. Thus, this is a feature, not a bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neuron = 35\n",
    "\n",
    "# Make a copy of the coordinate Series in order to preserve the original data.\n",
    "x_coords = mickey.spikes_and_beh[\"X_center\"].copy()\n",
    "y_coords = mickey.spikes_and_beh[\"Y_center\"].copy()\n",
    "\n",
    "x = x_coords.astype(int)\n",
    "y = y_coords.astype(int)\n",
    "\n",
    "# We need to create a vector of boolean values for when the (provided) neuron \n",
    "# fired and didn't fire. This is passed to the plot_heatmap function in order \n",
    "# to only create a heatmap based on where the neuron fired. \n",
    "weights = (mickey.spikes_and_beh[neuron] != 0).astype(int)\n",
    "weights = pd.Series(weights)\n",
    "\n",
    "title = \"{}, neuron {}\".format(mickey.name, neuron)\n",
    "\n",
    "visualize.plot_heatmap(x, y, sigma=2, title=title, bins=50, figsize=(6, 6), weights=weights, savefig=False);\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "# Now, we plot a scatterplot to compare the heatmap with the precise firing positions of the neuron. \n",
    "\n",
    "plt.figure(figsize=(6, 6));\n",
    "plt.scatter(x_coords, y_coords, marker='o');\n",
    "\n",
    "# Get the coordinates where the neuron actually fired.\n",
    "x_1 = x_coords.loc[mickey.spikes_and_beh[neuron] != 0]\n",
    "y_1 = y_coords.loc[mickey.spikes_and_beh[neuron] != 0]\n",
    "\n",
    "# Overlay the first scatterplot with a scatterplot of positions where the neuron fired.\n",
    "plt.scatter(x_1, y_1, marker='x', color='red');\n",
    "\n",
    "plt.title(title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Cell Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X and Y coordinate column vectors and cast all their values to int.\n",
    "x_coords = mickey.spikes_and_beh[\"X_center\"].astype(int)\n",
    "y_coords = mickey.spikes_and_beh[\"Y_center\"].astype(int)\n",
    "\n",
    "# Shift all coordinate values by increasing all of them by the minimum value. This\n",
    "# is necessary in order to apply the cantor pairing function, since the cantor \n",
    "# pairing function is only defined on the natural numbers, i.e., {0, 1, 2, 3, ...}.\n",
    "x_coords += abs(x_coords.min())\n",
    "y_coords += abs(y_coords.min())\n",
    "\n",
    "# Reduce the dimensionality of the coordinates, since sklearn's mutual information \n",
    "# function only allows you to compute the NMI between two arrays.\n",
    "z_coords = apply_cantor_pairing(x_coords.tolist(), y_coords.tolist())\n",
    "z_coords = pd.Series(data=z_coords)\n",
    "z_coords = z_coords.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmi_wrapper(dataframe, beh_col_vec):\n",
    "    \"\"\"Wrapper to apply sklearn's nmi function to each neuron column \n",
    "       vector of dataframe and a given behavior column vector.\n",
    "    \"\"\"\n",
    "    return dataframe.apply(normalized_mutual_info_score, args=(beh_col_vec,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time permutation_distributions = Resampler.shuffle(10000, mickey.spikes, nmi_wrapper, z_coords, flip_roll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_distributions.hist(alpha=0.5, color=\"pink\", bins=\"auto\", figsize=(23, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_statistics = nmi_wrapper(mickey.spikes, z_coords)\n",
    "original_statistics = original_statistics.to_dict()\n",
    "\n",
    "for neuron, original_stat in original_statistics.items():\n",
    "    p_value = Resampler.p_value(original_stat, permutation_distributions[neuron])\n",
    "    if p_value < 0.05:\n",
    "        print(\"neuron {}: p<{}\".format(neuron, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron, original_stat in original_statistics.items():\n",
    "    result = Resampler.two_tailed_test(original_stat, permutation_distributions[neuron])\n",
    "    print(\"neuron {}: result={}\".format(neuron, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Selectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the `shuffle` function in order to create a permutation distribution, for each neuron, of the difference of means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time permutation_distr = Resampler.shuffle(10000, mickey.spikes, Resampler.diff_of_mean_rate, mickey.spikes_and_beh[\"OpenArms_centerpoint\"], mickey.spikes_and_beh[\"ClosedArms_centerpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the permutation distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_distr.hist(alpha=0.5, color=\"green\", bins=\"auto\", figsize=(23, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classify cells by the behavior for which they are selective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_diff_of_means = dict(zip(mickey.spikes.columns, Resampler.diff_of_mean_rate(mickey.spikes, mickey.spikes_and_beh[\"OpenArms_centerpoint\"], mickey.spikes_and_beh[\"ClosedArms_centerpoint\"])))\n",
    "\n",
    "p_values = {}\n",
    "for neuron, original_stat in original_diff_of_means.items():\n",
    "    p_value = Resampler.p_value(original_diff_of_means[neuron], permutation_distr[neuron])\n",
    "    p_values[neuron] = p_value\n",
    "    print(\"neuron {}: p={}\".format(neuron, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_cells = {}\n",
    "\n",
    "for neuron, p_value in p_values.items():\n",
    "    if p_value < 0.05 and original_diff_of_means[neuron] > 0:\n",
    "        classified_cells[neuron] = \"OpenArms_centerpoint\"\n",
    "    elif p_value < 0.05 and original_diff_of_means[neuron] < 0:\n",
    "        classified_cells[neuron] = \"ClosedArms_centerpoint\"\n",
    "    elif p_value >= 0.05:\n",
    "        classified_cells[neuron] = \"Not-selective\"\n",
    "        \n",
    "classified_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot a pie chart in order to visualize the proportions of cells that are selective for behaviors of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_selective = 0\n",
    "closed_selective = 0\n",
    "not_seletive = 0\n",
    "\n",
    "for cell, classification in classified_cells.items():\n",
    "    if classification == \"OpenArms_centerpoint\":\n",
    "        open_selective += 1\n",
    "    elif classification == \"ClosedArms_centerpoint\":\n",
    "        closed_selective += 1\n",
    "    elif classification == \"Not-selective\":\n",
    "        not_seletive += 1\n",
    "        \n",
    "# Plot a pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "sizes = [open_selective, closed_selective, not_seletive]\n",
    "visualize.pie_chart(sizes, \"open selective\", \"closed selective\", \"not selective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The functions below are stand-alone functions meant to help with clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(dataframe, all_beh_intervals, **kwargs):    \n",
    "    \"\"\"Plot all the columns of a given dataframe.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas DataFrame\n",
    "        \n",
    "        all_beh_intervals: \n",
    "        \n",
    "        cmap: str, optional, default: 'viridis'\n",
    "            The colormap to use for coloring traces.\n",
    "    \n",
    "        hspace: float, optional, default: 0.0\n",
    "        \n",
    "        figsize: tuple, optional, default: (25, 20)\n",
    "        \n",
    "        trace_colors: list, optional, default: [0, 1, ..., n-1]\n",
    "            \n",
    "        \n",
    "        bg_colors: list, optional, default: None\n",
    "            \n",
    "        \n",
    "        bg_alpha: float, optional, default 0.1:\n",
    "            The transparency of the trace background colors.\n",
    "    \n",
    "        title: str, optional, default: None\n",
    "        \n",
    "        savefig: bool, optional, default: False\n",
    "            If True, the figure will be saved.\n",
    "            \n",
    "        dpi: int, optional, default: 600\n",
    "            \n",
    "        \n",
    "    \"\"\"\n",
    "    bg_colors = kwargs.get(\"bg_colors\", [\"blue\", \"orange\", \"red\"])\n",
    "    \n",
    "    if len(bg_colors) != len(all_beh_intervals):\n",
    "        raise ValueError(\"bg_colors and all_beh_intervals must be of equal length!!!\")\n",
    "        \n",
    "    trace_colors = kwargs.get(\"trace_colors\", [i for i, _ in enumerate(dataframe.columns)])\n",
    "    \n",
    "    if len(trace_colors) != len(dataframe.columns):\n",
    "        raise ValueError(\"Length of trace_colors must equal amount of columns in dataframe!!!\")    \n",
    "        \n",
    "    hspace = kwargs.get(\"hspace\", 0.0)\n",
    "    figsize = kwargs.get(\"figsize\", (25, 20))\n",
    "    colormap = kwargs.get(\"cmap\", \"viridis\")\n",
    "    cmap = plt.cm.get_cmap(colormap, len(trace_colors))\n",
    "    \n",
    "    _, axes = plt.subplots(len(dataframe.columns), 1, figsize=figsize)\n",
    "\n",
    "    for index, col_name in enumerate(dataframe.columns):\n",
    "        axes[index].plot(dataframe.index, dataframe[col_name], c=cmap(trace_colors[index]))\n",
    "        axes[index].axis(\"off\")\n",
    "        \n",
    "    for j, beh_intrvals in enumerate(all_beh_intervals):\n",
    "        [ax.axvspan(intrval[0], intrval[-1], alpha=0.5, facecolor=bg_colors[j]) for ax in axes for intrval in beh_intrvals] \n",
    "    \n",
    "    plt.subplots_adjust(wspace=0, hspace=hspace)\n",
    "    plt.title(kwargs.get(\"title\", None))\n",
    "    \n",
    "    if kwargs.get(\"savefig\", False):\n",
    "        plt.savefig(\"plots.pdf\", format=\"pdf\", dpi=600)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behavior_intervals = []\n",
    "\n",
    "for behavior in [\"OpenArms_centerpoint\", \"ClosedArms_centerpoint\", \"Center\"]:\n",
    "    epochs = extract_epochs(mickey, behavior)\n",
    "    behavior_intervals = filter_epochs(epochs[1], framerate=1, seconds=1)\n",
    "    all_behavior_intervals.append(behavior_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time plot_columns(mickey.cell_transients[[1, 2, 3, 4, 5]], all_behavior_intervals, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We find all possible clusters of neurons for drd87 in EPM during the overall session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.clustering import compute_connections\n",
    "from analysis.clustering import similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = compute_connections(mickey.spikes)\n",
    "neuron_network = NeuronNetwork(mickey.spikes.columns, connections)\n",
    "\n",
    "sim_matrix = similarity_matrix(mickey.spikes)\n",
    "clusters = affinity_propagation(sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We plot the imaged neurons by their actual positions, and we color code each neuron by its respective cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_colors = [clusters[key] for key in sorted(clusters.keys())]\n",
    "_, weights = zip(*nx.get_edge_attributes(neuron_network.network, \"weight\").items())\n",
    "_ = neuron_network.plot(node_color=node_colors, figsize=(10, 10), node_size=600, edge_color=weights, edge_cmap=plt.cm.Pastel1, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We plot the continuous time series plots, for each neuron that was assigned to a cluster with $2$ or more neurons. Each time series plot is color coded its respective cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behavior_intervals = []\n",
    "for behavior in [\"OpenArms_centerpoint\", \"ClosedArms_centerpoint\", \"Center\"]:\n",
    "    epochs = extract_epochs(mickey, behavior)\n",
    "    behavior_intervals = filter_epochs(epochs[1], framerate=1, seconds=1)\n",
    "    all_behavior_intervals.append(behavior_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = extract_clusters(clusters)\n",
    "plot_traces(mickey.spikes, clusters, all_beh_intervals=all_behavior_intervals, figsize=(25, 20), hspace=0.0, save=False, title=\"traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Theoretical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the mean betweeness centrality of drd87's neuron network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_network.mean_betw_cent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the average clustering coefficient for drd87's network of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(neuron_network.network, weight=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the average clustering coefficient for each extracted cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, cluster in clusters.items():\n",
    "    avg_cluster_coeff = np.mean(list(nx.clustering(neuron_network.network, weight=\"weight\", nodes=cluster).values()))\n",
    "    print(\"avg clustering coefficient of {} = {}\".format(cluster, avg_cluster_coeff))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the mean shortest path length of drd87's network of neurons. Recall: \"random and complex networks have short mean path lengths (high global efficiency of parallel information transfer)\" (Bullmore & Sporns 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_network.avg_shortest_path_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We the compute the degree assortativity of the neuron network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_pearson_correlation_coefficient(drd87_graph.network, weight=\"weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
