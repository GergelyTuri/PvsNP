{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevated-Plus Maze Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import analysis_utils as au\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Queue\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import SigProc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_directory = os.path.expanduser(\"~\") + \"/Hen_Lab/Mice/EPM\"\n",
    "\n",
    "if not os.path.exists(mouse_directory):\n",
    "    print(\"The mouse directory does not exist\", file=sys.stderr)\n",
    "\n",
    "file_num = 0\n",
    "raw_files = list()\n",
    "for dir_name, subdir_list, file_list in os.walk(mouse_directory):\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            print(\"{}. full path of: {} is: {}\".format(file_num, file_name, dir_name+\"/\"+file_name))\n",
    "            file_num += 1\n",
    "            raw_files.append(dir_name+\"/\"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au.run_epm_analysis(raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(raw_files[1], header=None)\n",
    "_, AUC_dataframe, cell_transients_dataframe = SigProc.detect_ca_transients_mossy(data, 2, 0.5, 0.2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "au.neuron_line_plot(AUC_dataframe, \"neuron38\", \"neuron45\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Discuss and streamline the below functionality, turn it into a function, make sure the function is sound, and move it to `analysis_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_column_names = ['Trial_time', 'Recording_time', 'X_center', 'Y_center', 'Area', 'Areachange', \n",
    "                         'Elongation', 'Distance_moved', 'Velocity', 'Arena_centerpoint',\n",
    "                         'Open1_centerpoint', 'Open2_centerpoint',\n",
    "                         'Closed1_centerpoint', 'Closed2_centerpoint',\n",
    "                         'OpenArms_centerpoint', 'ClosedArms_centerpoint', 'Result_1']\n",
    "\n",
    "behavior_df = pd.read_csv(raw_files[0], header=None)\n",
    "behavior_df.columns = behavior_column_names\n",
    "behavior_df = au.downsample_dataframe(behavior_df, 3)\n",
    "\n",
    "# Define what constitutes as a running frame\n",
    "VELOCITY_CUTOFF = 4;\n",
    "\n",
    "# Adds \"Running_frames\" column to the end of the behavior Dataframe \n",
    "behavior_df[\"Running_frames\"] = np.where(behavior_df[\"Velocity\"] > VELOCITY_CUTOFF, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_concated_behavior = AUC_dataframe.join(behavior_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_rate(dataframe, neuron_activity_df, *behaviors, frame_rate=10):\n",
    "    \"\"\"Computes difference between the rates of two behaviors\n",
    "    \n",
    "    Args: \n",
    "        dataframe: the the concatenated pandas DataFrame of an animal's neuron \n",
    "        activity and corresponding behavior\n",
    "        neuron_col_names: the names of the neuron columns in the DataFrame\n",
    "        *behaviors: a single or ordered pair of behaviors to compute the difference\n",
    "        rate for, e.g. \"Running\", e.g. \"ClosedArms\", \"OpenArms\"\n",
    "        frame_rate: the framerate associated with the given data; default is 10\n",
    "    \n",
    "    Returns:\n",
    "        a numpy array of all the means of the behavior vectors subtracted from the \n",
    "        corresponding means of the non-behavior vectors, all scaled by frame rate\n",
    "    \"\"\"\n",
    "    if len(behaviors) == 1:  \n",
    "        beh_vec = dataframe.loc[dataframe[behaviors[0]] != 0, neuron_activity_df.columns]\n",
    "        no_beh_vec = dataframe.loc[dataframe[behaviors[0]] == 0, neuron_activity_df.columns]\n",
    "        return frame_rate * (beh_vec.values.mean(axis=0) - no_beh_vec.values.mean(axis=0))\n",
    "    elif len(behaviors) == 2:\n",
    "        beh_vec = dataframe.loc[dataframe[behaviors[0]] != 0, neuron_activity_df.columns]\n",
    "        no_beh_vec = dataframe.loc[dataframe[behaviors[1]] != 0, neuron_activity_df.columns]\n",
    "        return frame_rate * (beh_vec.values.mean(axis=0) - no_beh_vec.values.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_diff_rate(neuron_concated_behavior, AUC_dataframe.columns, \"OpenArms_centerpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_real_diff_df(dataframe, neuron_act_df, behavior):\n",
    "    \"\"\"Compute the real difference mean values for all neurons\n",
    "    \n",
    "    Args:\n",
    "        dataframe: the concatenated pandas DataFrame of the neuron activity\n",
    "        DataFrame and corresponding behavior DataFrame, for a given animal\n",
    "        neuron_activity_df: the pandas DataFrame of neuron activity,\n",
    "        for a given animal\n",
    "        behavior: the behavior for which to compute the difference rate\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        real_df: a pandas DataFrame of with one row of all the real difference\n",
    "        values computed for all the neurons for a given animal\n",
    "    \"\"\"\n",
    "    real_df = pd.DataFrame(columns=neuron_act_df.columns, index=[\"d\"])\n",
    "    real_df.loc['d'] = compute_diff_rate(dataframe, neuron_act_df, behavior)\n",
    "    return real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_diff_df = set_real_diff_df(neuron_concated_behavior, AUC_dataframe, \"OpenArms_centerpoint\")\n",
    "real_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_worker(q, num_of_experiments, neuron_activity_df, neuron_and_behavior_df, behavior):\n",
    "    \"\"\"Helper function for shuffle()\n",
    "\n",
    "    Given a certain number of experiments to simulate, this function will\n",
    "    add a dataframe to a provided queue full of the amount of experiments \n",
    "    desired as obervations rows. \n",
    "    Note: This function is meant to be only be used as a helper function \n",
    "    for the shuffle() function\n",
    "\n",
    "    Args:\n",
    "        q: the blocking queue to which the resulting dataframe will be added to\n",
    "        num_of_experiments: the number of experiments that will be simulated \n",
    "        and appended, as observations, to the dataframe to be returned\n",
    "        neuron_activity_df: the neuron activity dataframe for a given mouse\n",
    "        neuron_and_behavior_df: the concatenated neuron activity and behavior \n",
    "        dataframes for a given mouse \n",
    "        behavior: the specific behavior to simulate the experiments on\n",
    "    \"\"\" \n",
    "    first_col = neuron_activity_df.columns[0]\n",
    "    last_col = neuron_activity_df.columns[len(neuron_activity_df.columns)-1]\n",
    "    shuffled_df = pd.DataFrame(columns=neuron_activity_df.columns)\n",
    "    \n",
    "    for index in range(num_of_experiments):\n",
    "        neuron_and_behavior_df.loc[:, first_col:last_col] = neuron_and_behavior_df.loc[:, first_col:last_col].sample(frac=1).reset_index(drop=True)\n",
    "        shuffled_df.loc[index] = compute_diff_rate(neuron_and_behavior_df, neuron_activity_df, behavior)\n",
    "\n",
    "    q.put(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(total_experiments, neuron_and_behavior_df, neuron_activity_df, behavior):\n",
    "    \"\"\"Homebrewed resampling function for EPM Analysis\n",
    "    \n",
    "    Resampling function that gives the capability to \"simulate\"\n",
    "    experiments using random shuffling of the observations for each \n",
    "    pandas dataframe. \n",
    "    \n",
    "    Args: \n",
    "        total_experiments: the total amount of epxeriments to simulate via bootstrapping\n",
    "        neuron_and_behavior_df: the concatenated neuron activity and behavior dataframes\n",
    "        for a given animal\n",
    "        neuron_activity_df: the neuron activity dataframe for a given animal\n",
    "        behavior: the specific behavior to simulate the experiments on\n",
    "    \n",
    "    Returns: a (vertically) concatenated pandas DataFrame of all the shuffled DataFrames \n",
    "    that all the shuffle_worker processes produced\n",
    "    \"\"\"\n",
    "    experiments_per_worker = total_experiments // os.cpu_count() \n",
    "    q = Queue()\n",
    "    processes = []\n",
    "    rets = []\n",
    "    for _ in range(0, os.cpu_count()):\n",
    "        p = Process(target=shuffle_worker, args=(q, experiments_per_worker, neuron_activity_df, neuron_and_behavior_df, behavior))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        ret = q.get()  # will block\n",
    "        rets.append(ret)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    return pd.concat(rets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped = shuffle(100000, neuron_concated_behavior, AUC_dataframe, \"OpenArms_centerpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_copy = bootstrapped.copy()\n",
    "col = 0\n",
    "for col in range(0, len(bootstrapped_copy.columns)):\n",
    "    bootstrapped_copy.iloc[:, col] += abs(bootstrapped_copy.min()[col])\n",
    "    col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for neuron in bootstrapped_copy:\n",
    "    plt.figure()\n",
    "    sns.distplot(bootstrapped_copy[neuron], color='m', fit=stats.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (bootstrapped_copy[\"neuron46\"].mean()**2) / bootstrapped_copy[\"neuron46\"].var()\n",
    "scale = (bootstrapped_copy[\"neuron46\"].var() / bootstrapped_copy[\"neuron46\"].mean())\n",
    "a\n",
    "scale\n",
    "scipy.stats.kstest(bootstrapped_copy[\"neuron46\"].values, 'gamma', args=(a, 0, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace (0, 20, 200) \n",
    "y1 = stats.gamma.pdf(x, a=a, scale=scale)\n",
    "\n",
    "plt.plot(x, y1);\n",
    "plt.ylim([0, 0.7]);\n",
    "plt.xlim([0, 8]);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: for `is_neuron_selective()`, make sure implementation is sound, write-up documentation, and move to analysis_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_neuron_selective(resampled_df, real_d_df, neuron, behavior_name, high_tail, low_tail):\n",
    "    \"\"\"Classifies a given neuron as selective or non-selective\n",
    "    \n",
    "    Classifies a given neuron as selective for a certain behavior, selective for \n",
    "    when that behavior is not performed, or non-selective. This is a custom function\n",
    "    for carrying out a two-tailed hypothesis test.\n",
    "    One can use this as a stand alone function to classify a single neuron for \n",
    "    a certain animal as either a <behavior> neuron, a \"Non\"-<behavior> neuron, or\n",
    "    a \"Non-selective\" neuron.\n",
    "    \n",
    "    Args: \n",
    "        resampled_df: a resampled pandas DataFrame\n",
    "        real_diff_df: a pandas DataFrame with one row that has the real difference of means\n",
    "        values for a given animal and a corresponding behavior\n",
    "        neuron: a single neuron of the neuron to classify use the 2-tailed hypothesis test\n",
    "        behavior_name: the behavior to classify the neuron by, e.g. \"Running\" or \"Non-Running\"\n",
    "        high_tail: the cutoff for the upper-tail of the distribution\n",
    "        low_tail: the cutoff for the lower-tail of the distribution\n",
    "    \n",
    "    Returns:\n",
    "        behavior_name, \"Non-\" + behavior_name, or \"Non-selective\" based on the result of the\n",
    "        two-tailed hypothesis test \n",
    "    \"\"\"\n",
    "    if real_d_df[neuron]['d'] >= np.percentile(resampled_df[neuron], high_tail):\n",
    "        return behavior_name\n",
    "    elif real_d_df[neuron]['d'] <= np.percentile(resampled_df[neuron], low_tail):\n",
    "        return \"Non-\" + behavior_name\n",
    "    else: \n",
    "        return \"Non-selective\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_neuron_selective(bootstrapped, real_diff_df, \"neuron50\", \"OpenArms\", 87.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_neurons_for_beh(resampled_df, real_diff_df, behavior_name, high_tail, low_tail):\n",
    "    \"\"\"Classifies a given set of neurons\n",
    "    \n",
    "    This function simply calls is_neuron_selective for all the neurons \n",
    "    for a given animal. \n",
    "    \n",
    "    Args: \n",
    "        resampled_df: a resampled pandas DataFrame\n",
    "        real_diff_df: a pandas DataFrame with one row that has the real difference of means\n",
    "        behavior_name: the behavior to classify each neuron by, e.g. \"Running\" or \"Non-Running\"\n",
    "        high_tail: the cutoff for the upper-tail of the distribution\n",
    "        low_tail: the cutoff for the lower-tail of the distribution\n",
    "    \n",
    "    Returns: \n",
    "        neurons_dict: a dictionary of all the neurons of a given animal as the keys,\n",
    "        with each key having a corresponding classifcation as its value\n",
    "    \"\"\"\n",
    "    neurons_dict = {}\n",
    "    for neuron in resampled_df.columns:\n",
    "        neurons_dict[neuron] = is_neuron_selective(resampled_df, real_diff_df, neuron, behavior_name, high_tail, low_tail)\n",
    "\n",
    "    return neurons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_neurons_for_beh(bootstrapped, real_diff_df, \"OpenArms_centerpoint\", 87.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_by_neurons(concated_df, neuron_names, *behaviors, frame_rate=10):\n",
    "    \"\"\"Computes the neuron activity rates for given behaviors\n",
    "    \n",
    "    This function computes the rates for a given animal's activity and  \n",
    "    neuron, given some set of behaviors.\n",
    "\n",
    "    Args: \n",
    "        concated_df: a concatenated pandas DataFrame of the neuron activity and \n",
    "        the corresponding behavior, for a given animal.\n",
    "        neuron_names: the names of the neurons whose rates are to be computed.\n",
    "        behaviors: a list of the behaviors for which to compute the activity rates. \n",
    "        frame_rate: the framerate to multiply the rate by, default is 10.\n",
    "\n",
    "    Returns: \n",
    "        activity_df: a pandas DataFrame of the neuron activity rates.\n",
    "    \"\"\"\n",
    "    activity_df = pd.DataFrame(columns=behaviors)\n",
    "    for behavior in behaviors:\n",
    "        if behavior in concated_df.columns:\n",
    "            activity_df.loc[:, behavior] = frame_rate * concated_df.loc[concated_df[behavior] != 0, neuron_names].mean()\n",
    "        elif '&' in behavior:\n",
    "            beh1 = behavior.split('&')[0]\n",
    "            beh2 = behavior.split('&')[1]\n",
    "            activity_df.loc[:, behavior] = frame_rate * concated_df.loc[(concated_df[beh1] != 0) & ((concated_df[beh2] != 0)), neuron_names].mean()\n",
    "        elif '|' in behavior:\n",
    "            beh1 = behavior.split('|')[0]\n",
    "            beh2 = behavior.split('|')[1]\n",
    "            activity_df.loc[:, behavior] = frame_rate * concated_df.loc[(concated_df[beh1] != 0) | ((concated_df[beh2] != 0)), neuron_names].mean()\n",
    "\n",
    "    return activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_rates_df = activity_by_neurons(neuron_concated_behavior, cell_transients_dataframe.columns, \"ClosedArms_centerpoint\", \"OpenArms_centerpoint\", \"OpenArms_centerpoint&Running_frames\", \"ClosedArms_centerpoint&Running_frames\", \"Running_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_activity_rates(*animals):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behavior_by_time(concated_df, behavior):\n",
    "    \"\"\"Split dataframe by time and behavior\n",
    "    \n",
    "    Args: \n",
    "        concated_df: a concatenated pandas DataFrame of the neuron activity and \n",
    "        the corresponding behavior, for a given animal.\n",
    "        behavior: the specific behavior for which to generate the time intervaled dataframes \n",
    "    \n",
    "    Returns: \n",
    "        time_bins: a dictionary of each intervaled dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create copy of the dataframe for a certain behavior\n",
    "    time_binned_df = concated_df.loc[concated_df[behavior] != 0].copy()\n",
    "    time_binned_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add a column of the trial time in the form of time deltas\n",
    "    x = pd.to_timedelta('0.1s')\n",
    "    time_binned_df.loc[:, \"TIME\"] = pd.Series(x*i for i in (time_binned_df.index))\n",
    "    \n",
    "    # Group the dataframe by 1 minute intervals\n",
    "    grouped = time_binned_df.set_index(\"TIME\").groupby(pd.Grouper(freq=\"1Min\"))\n",
    "    \n",
    "    # Place each dataframe that contains the data for every 1 minute intervals into a dictionary\n",
    "    time_bins = {}\n",
    "    minute = 0\n",
    "    for name, group in grouped:\n",
    "        time_bins[minute] = grouped.get_group(name)\n",
    "        minute += 1\n",
    "        \n",
    "    return time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_dfs = behavior_by_time(neuron_concated_behavior, \"OpenArms_centerpoint\")\n",
    "time_binned_dfs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
